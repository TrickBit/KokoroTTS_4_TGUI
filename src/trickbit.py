"""
TrickBit's KokoroTTS Core Logic Module

Separates business logic from UI concerns for better maintainability.
Handles voice management, audio processing, and TTS pipeline coordination.
All settings management is handled by the UI layer (script.py).
"""
import time
import importlib
import pathlib
from extensions.KokoroTTS_4_TGUI.src.kshared import ksettings, kruntime
from pydub import AudioSegment

# ============================================================================
# CORE INITIALIZATION AND SETUP
# ============================================================================

# Initialize extension paths and backend - must happen first
extension_dir = pathlib.Path(__file__).parent.parent  # Go up from src/ to extension root
extension_name = extension_dir.name

# Store in kruntime for global access
kruntime.set('extension_dir', extension_dir)
kruntime.set('extension_name', extension_name)
kruntime.set('backend', 'onnx')
kruntime.set('icon_style', 'png')

# Import debug and utility modules (safe - no circular dependencies)
from extensions.KokoroTTS_4_TGUI.src.debug import error_log, info_log, debug_log
from extensions.KokoroTTS_4_TGUI.src.splittext import clean_text_for_tts, simple_sentence_split
from extensions.KokoroTTS_4_TGUI.src import makehtml


# ============================================================================
# CORE BUSINESS LOGIC FOR ENTRY POINTS
# ============================================================================

def handle_input_modifier(string, state):
    """
    Purpose: Handle user input processing for text-generation-webui integration
    Pre: Valid input string from user, state object available
    Post: Processing message set for UI feedback
    Args: string (str) - User input text
          state - Chat state object from text-generation-webui
    Returns: str - Unmodified input string (we don't modify user input)
    """
    # Set processing message for UI feedback
    from extensions.KokoroTTS_4_TGUI.src.kshared import shared
    shared.processing_message = "*Is recording a voice message...*"
    return string


def handle_output_modifier(string, state):
    """
    Purpose: Handle AI response processing for text-generation-webui integration
    Pre: AI response generated by text-generation-webui
    Post: TTS audio processed and stored for UI retrieval
    Args: string (str) - AI response text
          state - Chat state object from text-generation-webui
    Returns: str - Original string unchanged (audio handled separately)
    """
    return process_ai_response(string, state)


# ============================================================================
# VOICE MANAGEMENT
# ============================================================================

def get_voice_display_mapping():
    """
    Purpose: Create mapping between UI display names and internal voice IDs
    Pre: Voice system available
    Post: Mapping dictionary created for UI components
    Args: None
    Returns: dict - Dictionary mapping display names to voice IDs

    Format: {"Emma - British Female": "bf_emma", ...}
    """
    voices_module = importlib.import_module('extensions.KokoroTTS_4_TGUI.src.onnx.voices')
    VOICES = voices_module.get_voices()  # Get voices list when needed
    display_mapping = {}

    for voice_id in VOICES:
        if voice_id.startswith('m'):  # Blended voices
            prefix_map = {'mf_': 'Blended Female', 'mm_': 'Blended Male', 'mx_': 'Blended Character'}
            suffix = prefix_map.get(voice_id[:3], voice_id)
            display_name = f"{voice_id[3:].title()} - {suffix}"
        else:  # Physical voices
            voice_info = voices_module.get_voice_info(voice_id)
            display_name = f"{voice_info['display_name']} - {voice_info['country']} {voice_info['gender']}"

        display_mapping[display_name] = voice_id

    return display_mapping


def get_sorted_display_names():
    """
    Purpose: Get voice display names sorted by language and gender priority
    Pre: Voice mapping system available
    Post: Sorted list created for UI dropdowns
    Args: None
    Returns: tuple - (sorted_names_list, voice_mapping_dict) for UI components

    Sorting priority: American > British > European > Other languages, Female > Male within each
    """
    mapping = get_voice_display_mapping()

    def sort_key(display_name):
        """
        Purpose: Generate sort key for voice display name prioritization
        Pre: Valid display name with " - " separator format
        Post: Tuple created for sorting comparison
        Args: display_name (str) - Voice display name
        Returns: tuple - (language_priority, gender_priority, name) for sorting
        """
        suffix = display_name.split(" - ", 1)[1] if " - " in display_name else display_name
        name = display_name.split(" - ", 1)[0] if " - " in display_name else display_name

        priority_map = {
            'American Female': (0, 0), 'American Male': (0, 1),
            'British Female': (1, 0), 'British Male': (1, 1),
            'European Female': (2, 0), 'European Male': (2, 1),
            'French Female': (3, 0), 'French Male': (3, 1),
            'Italian Female': (4, 0), 'Italian Male': (4, 1),
            'Japanese Female': (5, 0), 'Japanese Male': (5, 1),
            'Portuguese Female': (6, 0), 'Portuguese Male': (6, 1),
            'Chinese Female': (7, 0), 'Chinese Male': (7, 1),
            'Hindi Female': (8, 0), 'Hindi Male': (8, 1),
            'Blended Female': (9, 0), 'Blended Male': (9, 1), 'Blended Character': (9, 2)
        }

        priority = priority_map.get(suffix, (99, 99))
        return (*priority, name)

    sorted_names = sorted(mapping.keys(), key=sort_key)
    return sorted_names, mapping


def substitute_placeholders(text, voice):
    """
    Purpose: Replace placeholder tokens with actual voice information
    Pre: Valid text with placeholders, valid voice identifier
    Post: Placeholders replaced with voice-specific information
    Args: text (str) - Text containing {VNAME} and {VREGION} placeholders
          voice (str) - Voice identifier for replacement values
    Returns: str - Text with placeholders replaced by voice information
    """
    voice_name = voice[3:].capitalize() if len(voice) > 3 else voice.capitalize()
    region = ""

    if voice.startswith('mf_'):
        region = " (blended female voice)"
    elif voice.startswith('mm_'):
        region = " (blended male voice)"
    elif voice.startswith('mx_'):
        region = " (blended character voice)"
    elif voice.startswith(('bf_', 'bm_')):
        region = " from the UK"
    elif voice.startswith(('af_', 'am_')):
        region = " from the US"
    elif voice.startswith('ef_'):
        region = " from Europe"
    elif voice.startswith('ff_'):
        region = " from France"
    elif voice.startswith(('hf_', 'hm_')):
        region = " from India"
    elif voice.startswith(('if_', 'im_')):
        region = " from Italy"
    elif voice.startswith(('jf_', 'jm_')):
        region = " from Japan"
    elif voice.startswith(('pf_', 'pm_')):
        region = " from Portugal"
    elif voice.startswith(('zf_', 'zm_')):
        region = " from China"

    return text.replace("{VNAME}", voice_name).replace("{VREGION}", region)


# ============================================================================
# AUDIO PROCESSING
# ============================================================================

def generate_voice_preview(preview_text):
    """
    Purpose: Generate voice preview with audio controls for UI testing
    Pre: Voice system available, valid preview text provided
    Post: Audio file generated and HTML controls created
    Args: preview_text (str) - Text to speak for preview
    Returns: str - HTML string containing preview text and audio controls
    """
    speed = ksettings.get('speed', 1.0)
    pitch = ksettings.get('pitch', 1.0)
    voice_name = ksettings.get('voice', 'bf_emma')

    substituted_text = substitute_placeholders(preview_text, voice_name)
    string_for_tts = clean_text_for_tts(substituted_text, preprocess_code=False)

    try:
        generate = importlib.import_module('extensions.KokoroTTS_4_TGUI.src.onnx.generate')
        makehtml_module = importlib.reload(makehtml)

        msg_id = generate.run(string_for_tts, preview=True, pitch=pitch)
        if msg_id:
            extension_name = kruntime.get('extension_name')
            file_url = f"/file/extensions/{extension_name}/audio/preview.wav"
            play_html = makehtml_module.create_speaker_button_html(file_url, speed, preview_text)
            return f"Preview: {substituted_text} {play_html}"
    except Exception as e:
        error_log(f"Preview generation error: {e}")
        return f"Preview: {substituted_text} (Audio generation failed)"

    return f"Preview: {substituted_text}"


# ============================================================================
# TTS OUTPUT PROCESSING
# ============================================================================

def process_ai_response(string, state):
    """
    Purpose: Main TTS processing pipeline for AI responses
    Pre: TTS system available, AI response text provided
    Post: Audio HTML stored in kruntime for UI retrieval
    Args: string (str) - AI response text to convert to speech
          state - Chat state object (unused but required for interface)
    Returns: str - Original string unchanged (audio handled via kruntime state)
    """
    if not ksettings.get('enable_tts', False):
        info_log("TTS disabled")
        return string

    preprocess_code = ksettings.get('preprocess_code', True)
    string_for_tts = clean_text_for_tts(string, preprocess_code)

    if not string_for_tts.strip():
        info_log("No text after cleaning")
        return string

    experimental_mode = ksettings.get('experimental', False)
    if experimental_mode:
        return generate_chunked_audio(string, string_for_tts)
    else:
        return generate_standard_audio(string, string_for_tts)


def generate_standard_audio(original_string, clean_text):
    """
    Purpose: Generate single audio file for standard TTS output
    Pre: Voice loaded, clean text ready for processing
    Post: Audio file created and HTML stored in kruntime
    Args: original_string (str) - Original AI response text
          clean_text (str) - Preprocessed text ready for TTS
    Returns: str - Original string unchanged
    """
    speed = ksettings.get('speed', 1.0)
    pitch = ksettings.get('pitch', 1.0)
    voice_name = ksettings.get('voice', 'bf_emma')

    try:
        generate = importlib.import_module('extensions.KokoroTTS_4_TGUI.src.onnx.generate')
        makehtml_module = importlib.reload(makehtml)

        # Ensure voice loaded
        generate.load_voice(voice_name)

        msg_id = generate.run(clean_text, pitch=pitch)
        if msg_id is None:
            error_log("Audio generation failed")
            return original_string

        extension_name = kruntime.get('extension_name')
        file_url = f"/file/extensions/{extension_name}/audio/{msg_id}.wav"

        audio_html = makehtml_module.create_ai_audio_html(file_url, speed, clean_text[:50])
        kruntime.set('current_audio_html', audio_html)

        info_log(f"Audio generated: {len(audio_html)} chars HTML")
        return original_string

    except Exception as e:
        error_log(f"Audio generation error: {e}")
        return original_string


def generate_chunked_audio(original_string, clean_text):
    """
    Purpose: EXPERIMENTAL - Generate chunked audio for streaming playback
    Pre: Voice loaded, clean text available for chunking
    Post: Multiple audio files created with streaming HTML (when implemented)
    Args: original_string (str) - Original AI response text
          clean_text (str) - Preprocessed text ready for chunking
    Returns: str - Original string with chunked audio handling

    Note: Currently falls back to standard mode - streaming implementation pending
    """
    info_log("Experimental chunked mode - generating multiple audio files")

    # For now, fall back to standard mode
    # TODO: Implement proper chunking for large responses
    info_log("Chunked mode not fully implemented - falling back to standard")
    return generate_standard_audio(original_string, clean_text)


# ============================================================================
# UI SUPPORT FUNCTIONS
# ============================================================================

def get_current_audio_html():
    """
    Purpose: Retrieve stored audio HTML for UI button functionality
    Pre: Audio HTML may be stored in kruntime
    Post: HTML retrieved for UI display
    Args: None
    Returns: str - Current audio HTML or empty string if none available
    """
    return kruntime.get('current_audio_html', '')


def apply_splitting_method(method):
    """
    Purpose: Apply text splitting method change to audio generator
    Pre: Valid splitting method string provided
    Post: Splitting method applied to audio generator
    Args: method (str) - Splitting method name ('Split by sentence', etc.)
    Returns: None
    """
    try:
        generate = importlib.import_module('extensions.KokoroTTS_4_TGUI.src.onnx.generate')
        generate.set_splitting_type(method)
        info_log(f"Splitting method applied: {method}")
    except Exception as e:
        error_log(f"Error applying splitting method: {e}")


def load_stored_audio_for_ui():
    """
    Purpose: Load stored audio HTML when AI responds for UI auto-update
    Pre: Audio generation may have completed, UI components waiting for update
    Post: UI updated with new audio controls if new content available
    Args: None
    Returns: tuple - (audio_html, button_update_dict) for UI components or (None, None) for no change
    """
    audio_html = kruntime.get('current_audio_html', '')
    last_audio_html = kruntime.get('last_loaded_audio_html', '')

    # Only act if there's new audio content
    if audio_html and audio_html != last_audio_html:
        # Mark this audio as loaded to prevent re-loading
        kruntime.set('last_loaded_audio_html', audio_html)
        info_log(f"Auto-loading NEW audio into hidden div: {len(audio_html)} chars")
        return audio_html, {"value": "Pause", "interactive": True}
    elif audio_html:
        # Same audio, no update needed
        return None, None  # No change
    else:
        # No audio available
        return "", {"value": "Speak", "interactive": False}


# ============================================================================
# UTILITY FUNCTIONS
# ============================================================================

def generate_default_preview_text():
    """
    Purpose: Create default preview text template with voice placeholders
    Pre: None
    Post: Template string created with substitution placeholders
    Args: None
    Returns: str - Template with {VNAME} and {VREGION} placeholders for voice info
    """
    return "Hello, I'm {VNAME}{VREGION}, how are you today?"


def get_voice_id_from_display(display_name):
    """
    Purpose: Convert display name back to voice ID for settings storage
    Pre: Valid display name from UI dropdown
    Post: None
    Args: display_name (str or list) - Voice display name from Gradio
    Returns: str - Voice ID for internal use
    """
    # Handle case where Gradio passes a list instead of string
    if isinstance(display_name, list):
        display_name = display_name[0] if display_name else None

    if not display_name:
        return 'bf_emma'  # Safe fallback

    mapping = get_voice_display_mapping()
    return mapping.get(display_name, 'bf_emma')
